{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine data: A data wrangling example\n",
    "\n",
    "![](images/wine.png) \n",
    "\n",
    "## About the data\n",
    "The data is a results of a chemical analysis of wines grown in the same region in Italy, but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "\n",
    "It was made available on the UCI Machine Learning repository for exploratory data analysis and classification. [Source](https://archive.ics.uci.edu/ml/datasets/wine)\n",
    "\n",
    "## Data wrangling\n",
    "\n",
    "The goal of this notebook is to explain how to use Pandas to wrangle our data.\n",
    "\n",
    "What is data wrangling? Data wrangling the process of transforming and mapping data from one \"raw\" data form into another format, with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.\n",
    "\n",
    "But why Pandas? \n",
    "Pandas is a Python library developed specifically for data analysis, that allows you to easily: \n",
    "- Select and filter your dataset. \n",
    "- Automate the cleaning of your datasets, e.g. missing values. \n",
    "- Merge & transform datasets\n",
    "- Split-apply-combine: the ability to chunk your data set into pieces, apply a function, and place it back together is the number one reason to use Pandas. \n",
    "- Handling time series operations. Pandas is amazing at converting to different periods, resampling, etc are a brilliant feature.\n",
    "- Speed: When working with large datasets, it is much faster than tools like excel.\n",
    "\n",
    "\n",
    "\n",
    "## Wine dataset analysis \n",
    "The goal of this notebook is to explain how to use Pandas to wrangle our data.\n",
    "\n",
    "What is data wrangling? Data wrangling the process of transforming and mapping data from one \"raw\" data form into another format, with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.\n",
    "\n",
    "In this notebook, we will analyse a dataset about wine. We will cover: \n",
    "\n",
    "1. Loading the data\n",
    "2. Exploring the dataset\n",
    "3. High-level statistics properties of the dataset\n",
    "4. Plotting the data\n",
    "5. Create new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading in the data\n",
    "\n",
    "\n",
    "Pandas is a sepcialised package that allows us to work with databases using python.\n",
    "\n",
    "First we need to import the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to read in a csv file we can use\n",
    "```python\n",
    "pd.read_csv('filepath/file.csv')\n",
    "```\n",
    "\n",
    "We are going to read in the `wine_dataset.csv` which is in our `data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/wine_dataset.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the ';'? By default, Pandas will assume the csv file is exactly that: a comma-separated file. However, in our wine dataset, the entries are separated not by commas, but my semi-colons. Therefore, we add the `delimiter=';'` to make Pandas aware of this. \n",
    "\n",
    "\n",
    "As we have loaded in the data, we can display it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the dataset\n",
    "\n",
    "We have loaded in our data. Next up, it's time to highlight some tools for getting an initial understanding of what data our dataset contaings. \n",
    "\n",
    "We will explore the dataset using the following tools: \n",
    "* Checking the shape (`df.shape`) of the dataframe\n",
    "* The length (`len(df)`) of the dataframe\n",
    "* General information (`df.info()`) of the dataframe & columns\n",
    "* Fetching the first/last or a sample of a few rows (`.head()` `df.sample()` `df.tail()`)\n",
    "* The column names (`df.columns`)\n",
    "* Selecting one (or more) columns (`df['column_name']`)\n",
    "* Fetching the unique values of a column (`df['column_name'].unique()`)\n",
    "* Summing the amount of unique values of a column (`df['column_name'].value_counts()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Now we have a feel for the dataset, what would we do with it? Write down a few ideas in the chat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistics of the dataset\n",
    "\n",
    "We now have a rough idea of what our individual data points are like. However, we might like to calculate some high-level statistics over our dataset as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes our entire dataset. However, we have many different columns in our dataset. Maybe we're just interested in various statistics of one specific column. \n",
    "\n",
    "Remember how to select a single column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcohol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcohol'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interested in multiple columns? No problem! Notice the double brackets! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['alcohol', 'color_intensity']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermezzo: chaining commands\n",
    "\n",
    "So what's actually happening here? Well, we're chaining together a bunch of different commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more we chain together commands, the longer the line length becomes. A different way of writing down the exact same thing is by spreading it out over different lines (between round brackets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .head(10)\n",
    "    .tail(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    [['alcohol', 'color_intensity']]\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen how to calculate statistics over the whole dataset, what if we are interested in how these statistics vary over different parts of the dataset? \n",
    "\n",
    "For instance, for this dataset, we know that we have three different _classes_ of wine. We previously calculated the mean value of alcohol over the whole dataset, but how does the mean value differ per class?\n",
    "\n",
    "This is where a nifty little feature called `groupby` comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('class')\n",
    "    ['alcohol']\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plotting\n",
    "\n",
    "We previously explored the dataset through calculating statistics. However, a neat way to explore your dataset is to create visualisations as well! \n",
    "\n",
    "Although there are quite some visualisation Python packages out there, that allow you a whole lot of freedom when it concerns creating your plots, Pandas has some built-in plotting functionality as well based on `matplotlib`.\n",
    "\n",
    "We use the [`.plot()`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html) method on a DataFrame to create plot, e.g.\n",
    "\n",
    "    *dataframe*.plot(x = ..., y =..., kind =..., ...)\n",
    "    \n",
    "The `.plot()` method takes several optional parameters. Most notably the *kind* parameter, which accepts eleven different string values and determines which kind of plot youâ€™ll create:\n",
    "\n",
    "1. \"area\" is for area plots.\n",
    "2. \"bar\" is for vertical bar charts.\n",
    "3. \"barh\" is for horizontal bar charts.\n",
    "4. \"box\" is for box plots.\n",
    "5. \"hexbin\" is for hexbin plots.\n",
    "6. \"hist\" is for histograms.\n",
    "7. \"kde\" is for kernel density estimate charts.\n",
    "8. \"density\" is an alias for \"kde\".\n",
    "9. \"line\" is for line graphs.\n",
    "10. \"pie\" is for pie charts.\n",
    "11. \"scatter\" is for scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='color_intensity',  y='alcohol', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice, simple plot! However, we can do some more advanced stuff as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('class')\n",
    "    ['alcohol', 'color_intensity', 'ash']\n",
    "    .mean()\n",
    "    .plot(kind='bar')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: add the standard deviation as well! \n",
    "(\n",
    "    df\n",
    "    .groupby('class')\n",
    "    ['color_intensity']\n",
    "    .agg(['mean', 'std'])\n",
    "    .plot(y='mean', kind='bar', yerr='std')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may be interested in is the correlation between features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df[df.columns].corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this might be quite difficult to read and interpret.. we can create a heatmap to visualise the intensity of the values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "sns.heatmap(correlations, annot=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "- What two columns have the highest positive correlation? \n",
    "- What two columns have the highest negative correlation?\n",
    "- Did you find anything interesting or unexpected in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating new columns\n",
    "\n",
    "Sometimes, you want to do more than just explore the data you have at hand. You might, for instance, want to create new columns based on the data you have! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Demean the alcohol values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcohol'] - df['alcohol'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['demeaned_alcohol'] = df['alcohol'] - df['alcohol'].mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Decide which wines should be labeled at 'dark'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['color_intensity'] > df['color_intensity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dark_label'] = df['color_intensity'] > df['color_intensity'].median()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Give the label 'dark' or 'light'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['light' if x < df['color_intensity'].median() else 'dark' for x in df['color_intensity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_color'] = ['light' if x < df['color_intensity'].median() else 'dark' for x in df['color_intensity']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A more chainable way.._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .assign(demeaned_malic_acid = lambda d: d['malic_acid'] - d['malic_acid'].mean())\n",
    "    [['malic_acid', 'demeaned_malic_acid']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, we've simply covered some of the basics of what you can do with Pandas. We've seen: \n",
    "- How to load in your data from a .csv file with `pd.read_csv` and a delimiter. \n",
    "- How to explore the dataset to get a rough intuition for the data with various tools like `.shape`, `.columns`, `.info()` and `.head()`\n",
    "- How to retrieve some high-level statistics with `.describe()`, `.mean()` or `.median()` on the dataset as a whole _and_ on subsets of the data. \n",
    "- How to plot our data\n",
    "- How to add new columns to our data, e.g. the demeaned values. \n",
    "\n",
    "# What's Next\n",
    "\n",
    "But there is more! Our Python for Data Analysts covers a variety of topics on Pandas, such as: \n",
    "\n",
    "- Advanced selecting and filtering\n",
    "- Aggregations\n",
    "- Creating (advanced) columns\n",
    "- Combining datasets\n",
    "- Transformations\n",
    "- Advanced plotting\n",
    "- Time series\n",
    "- Pandas best practices\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
